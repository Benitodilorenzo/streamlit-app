# app_expert_card_gpt5.py
# Single-file Streamlit app â€” GPT-5 only, Hosted Web Search, async media, minimal prompting
# Includes patches:
#  (1) Placeholder image generation compatible with Pillow â‰¥10 (uses textbbox, not textsize)
#  (2) Hosted web_search errors are surfaced (not swallowed) + preflight check + UI notes
#
# Requirements:
#   pip install streamlit openai pillow requests
# Environment:
#   OPENAI_API_KEY  (required)
# Optional:
#   OPENAI_GPT5_SNAPSHOT (defaults to gpt-5-2025-08-07)
#   OPENAI_CHAT_MODEL    (defaults to snapshot)

import os, re, uuid, urllib.parse, json
from typing import List, Dict, Any, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor, Future

import requests
import streamlit as st
from PIL import Image, ImageDraw, ImageFont
from openai import OpenAI

# =========================
# CONFIG
# =========================
APP_TITLE = "ðŸŸ¡ Expert Card â€” GPT-5 (Hosted Web Search, Async, Single File)"
MODEL_SNAPSHOT = os.getenv("OPENAI_GPT5_SNAPSHOT", "gpt-5-2025-08-07")  # snapshot pin
OPENAI_MODEL = os.getenv("OPENAI_CHAT_MODEL", MODEL_SNAPSHOT)            # GPT-5 only

HTTP_TIMEOUT = 10
MEDIA_MAX_WORKERS = 4
PLACEHOLDER_MIN_TEXT = 3

MEDIA_DIR = os.path.join(os.getcwd(), "media")
os.makedirs(MEDIA_DIR, exist_ok=True)
UA = "ExpertCard/1.0 (+https://local.app) Streamlit"

# Prefer official/authoritative sources for images
PREFERRED_DOMAINS = {
    "book":    ["m.media-amazon.com", "amazon.de", "books.google.com", "openlibrary.org", "wikipedia.org"],
    "podcast": ["podcasts.apple.com", "itunes.apple.com", "spotify.com"],
    "person":  ["wikipedia.org", "wikidata.org"],
    "tool":    ["wikipedia.org", "docs.", "developer."],
    "film":    ["wikipedia.org", "themoviedb.org", "imdb.com"]
}

# =========================
# OPENAI CLIENT
# =========================
def get_client() -> OpenAI:
    key = os.getenv("OPENAI_API_KEY", "")
    if not key:
        raise RuntimeError("OPENAI_API_KEY is missing")
    return OpenAI(api_key=key)

client: Optional[OpenAI] = None

# =========================
# SESSION / STATE
# =========================
def init_state():
    if st.session_state.get("initialized"):
        return
    st.session_state.initialized = True

    # dialog history for UI (assistant/user only)
    st.session_state.history: List[Dict[str, Any]] = []

    # slots: up to 4 (S1..S4)
    st.session_state.slots: Dict[str, Dict[str, Any]] = {}
    st.session_state.slot_order = ["S1", "S2", "S3", "S4"]
    st.session_state.current_slot_ix = 0

    # dedupe for media jobs (entity_type+entity_name)
    st.session_state.media_fingerprints: set = set()

    # async executor & jobs
    st.session_state.executor = ThreadPoolExecutor(max_workers=MEDIA_MAX_WORKERS)
    st.session_state.media_jobs: Dict[str, Tuple[str, Future]] = {}

    # finalized lines
    st.session_state.final_lines: Dict[str, str] = {}

    # web_search preflight
    st.session_state.web_search_ok = None
    st.session_state.web_search_err = ""

def current_slot_id() -> str:
    ix = st.session_state.current_slot_ix
    return st.session_state.slot_order[min(ix, 3)]

def advance_slot():
    st.session_state.current_slot_ix = min(st.session_state.current_slot_ix + 1, 3)

# =========================
# UTILS
# =========================
def _get(url, params=None, headers=None, timeout=HTTP_TIMEOUT):
    h = {"User-Agent": UA}
    if headers: h.update(headers)
    return requests.get(url, params=params, headers=h, timeout=timeout)

def generate_placeholder_icon(text: str, slot_id: str) -> str:
    """Patch (1): Pillow â‰¥10 compatible placeholder (textbbox)."""
    size = (640, 640)
    img = Image.new("RGB", size, color=(24, 31, 55))
    draw = ImageDraw.Draw(img)
    for r, col in [(260, (57, 96, 199)), (200, (73, 199, 142)), (140, (255, 205, 86))]:
        draw.ellipse([(size[0]//2 - r, size[1]//2 - r), (size[0]//2 + r, size[1]//2 + r)], outline=col, width=8)

    txt = (text or "Idea").strip()
    if len(txt) < PLACEHOLDER_MIN_TEXT:
        txt = "Idea"
    try:
        font = ImageFont.truetype("DejaVuSans-Bold.ttf", 42)
    except Exception:
        font = ImageFont.load_default()

    # Pillow â‰¥10: textbbox; fallback to textsize if necessary
    try:
        bbox = draw.textbbox((0, 0), txt, font=font)
        w, h = bbox[2] - bbox[0], bbox[3] - bbox[1]
    except Exception:
        w, h = draw.textsize(txt, font=font)

    draw.text(((size[0]-w)//2, (size[1]-h)//2), txt, fill=(240, 240, 240), font=font)
    path = os.path.join(MEDIA_DIR, f"{slot_id}_ph.png")
    img.save(path, format="PNG")
    return path

def save_uploaded_image(file, slot_id: str) -> str:
    try:
        img = Image.open(file)
        path = os.path.join(MEDIA_DIR, f"{slot_id}_upload.png")
        img.save(path, format="PNG")
        return path
    except Exception:
        return ""

def normalize_entity(raw: str) -> Tuple[Optional[str], Optional[str]]:
    """
    Try to detect a public entity & normalize to (type, name).
    Returns (entity_type, entity_name) or (None, None).
    Heuristics + simple patterns; backed by GPT router (below).
    """
    s = (raw or "").strip()
    if not s: return (None, None)

    # Quick patterns for book title + author
    m = re.search(r'["â€œ]?([^"\n]+?)["â€]?\s+(?:by|von|from)\s+([A-Za-zÃ€-Ã–Ã˜-Ã¶Ã¸-Ã¿\.\-\s]+)$', s, re.I)
    if m:
        title = m.group(1).strip()
        author = m.group(2).strip()
        return ("book", f"{title} â€” {author}")

    # If looks like a film
    if re.search(r'\bmovie|film|poster\b', s, re.I):
        return ("film", s.replace("poster", "").strip(' "'))

    # If it looks like a person "Firstname Lastname" â†’ ambiguous, router decides
    if len(s.split()) in (2, 3) and s[0].isupper():
        return (None, None)

    return (None, None)

# =========================
# GPT-5 (Responses API) SCHEMAS
# =========================
BEST_IMAGE_SCHEMA = {
    "name": "BestImage",
    "schema": {
        "type": "object",
        "properties": {
            "url":        {"type":"string", "description":"Direct image URL (.jpg/.png), not HTML page"},
            "page_url":   {"type":"string", "description":"Canonical source page"},
            "source":     {"type":"string", "description":"Hostname of source"},
            "confidence": {"type":"number"},
            "reason":     {"type":"string"}
        },
        "required": ["url", "page_url"]
    },
    "strict": True
}

ENTITY_SCHEMA = {
    "name": "EntityPick",
    "schema": {
        "type": "object",
        "properties": {
            "detected": {"type":"boolean"},
            "entity_type": {"type":"string", "enum":["book","podcast","person","tool","film","none"]},
            "entity_name": {"type":"string", "description":"Human-readable; for books prefer 'Title â€” Author' if possible"}
        },
        "required": ["detected","entity_type","entity_name"]
    },
    "strict": True
}

INSIGHT_SCHEMA = {
    "name": "InsightBullets",
    "schema": {
        "type":"object",
        "properties":{
            "label":{"type":"string"},
            "bullets":{"type":"array","items":{"type":"string"},"minItems":2,"maxItems":4}
        },
        "required":["label","bullets"]
    },
    "strict": True
}

# =========================
# GPT-5 HELPERS (Hosted Web Search + Structured outputs)
# =========================
def hosted_search_best_image(entity_type: str, entity_name: str) -> Dict[str, Any]:
    """
    Use GPT-5 Responses API with hosted web_search to pick ONE authoritative image.
    Patch (2): Do NOT swallow errors â€” return status=error with notes.
    """
    prefer = PREFERRED_DOMAINS.get(entity_type, [])
    instructions = (
        "Find ONE authoritative image for the given public item.\n"
        f"Item type: {entity_type}\n"
        f"- Prefer domains: {', '.join(prefer) if prefer else 'no preference'}\n"
        "- MUST return a direct image URL (.jpg or .png), not a page.\n"
        "- Avoid thumbnails, memes, watermarks, wrong items.\n"
        "Return structured JSON only."
    )
    try:
        resp = client.responses.create(
            model=OPENAI_MODEL,
            tools=[{"type":"web_search"}],
            tool_choice="auto",
            reasoning={"effort":"minimal"},
            verbosity="low",
            response_format={"type":"json_schema","json_schema": BEST_IMAGE_SCHEMA},
            input=[{
                "role":"user",
                "content":[
                    {"type":"text","text":instructions},
                    {"type":"input_text","text": f"Item: {entity_name}"}
                ]
            }]
        )
        data = getattr(resp, "output_parsed", None) or getattr(resp, "output", None)
        if isinstance(data, dict) and data.get("url") and data.get("page_url"):
            return {"status":"found","best_image_url": data["url"], "candidates":[data], "notes": data.get("reason","")}
        return {"status":"error","best_image_url":"","candidates":[],"notes":"web_search returned no structured result"}
    except Exception as e:
        return {"status":"error","best_image_url":"","candidates":[],"notes": f"web_search error: {e}"}

def preflight_web_search():
    """One-time probe to detect if hosted web_search is available and callable."""
    try:
        resp = client.responses.create(
            model=OPENAI_MODEL,
            tools=[{"type":"web_search"}],
            tool_choice="auto",
            reasoning={"effort":"minimal"},
            verbosity="low",
            response_format={"type":"json_schema","json_schema": BEST_IMAGE_SCHEMA},
            input=[{"role":"user","content":[
                {"type":"text","text":"Test web search availability. Return any valid JSON per schema."}
            ]}]
        )
        _ = getattr(resp, "output_parsed", None) or getattr(resp, "output", None)
        st.session_state.web_search_ok = True
    except Exception as e:
        st.session_state.web_search_ok = False
        st.session_state.web_search_err = str(e)

def route_entity_with_gpt(text: str) -> Tuple[Optional[str], Optional[str]]:
    """Lightweight router: GPT-5 classifies and normalizes entity name."""
    try:
        resp = client.responses.create(
            model=OPENAI_MODEL,
            reasoning={"effort":"minimal"},
            verbosity="low",
            response_format={"type":"json_schema","json_schema": ENTITY_SCHEMA},
            input=[{"role":"user","content":[{"type":"text","text": f"Extract one public entity if present from: {text}"}]}]
        )
        data = getattr(resp, "output_parsed", None) or getattr(resp, "output", None)
        if isinstance(data, dict) and data.get("detected") and data.get("entity_type") != "none":
            return (data.get("entity_type"), data.get("entity_name"))
    except Exception:
        pass
    return (None, None)

def distill_insights_with_gpt(text: str, context_hint: str = "") -> Tuple[Optional[str], List[str]]:
    """Extract a short label + 2â€“4 bullets from the user's explanation."""
    try:
        inst = (
            "From the user's message, extract one concise label and 2â€“4 crisp bullets (facts/insights). "
            "No fluff, keep it specific. If context mentions a book/person/tool, you may reference it once."
        )
        if context_hint:
            inst += f" Context: {context_hint}"
        resp = client.responses.create(
            model=OPENAI_MODEL,
            reasoning={"effort":"minimal"},
            verbosity="low",
            response_format={"type":"json_schema","json_schema": INSIGHT_SCHEMA},
            input=[{"role":"user","content":[{"type":"text","text": inst}, {"type":"input_text","text": text}]}]
        )
        data = getattr(resp, "output_parsed", None) or getattr(resp, "output", None)
        if isinstance(data, dict) and data.get("label") and data.get("bullets"):
            bullets = [b for b in data["bullets"] if isinstance(b,str)]
            return (data["label"], bullets[:4])
    except Exception:
        pass
    return (None, [])

def finalize_card_with_gpt(notes: List[Dict[str, Any]]) -> Dict[str, str]:
    """Strict, minimal finalizer (4 labeled lines) via Chat Completions."""
    prompt = (
        "Create a concise Expert Card with exactly 4 labeled items.\n"
        "Each item: 1â€“2 short sentences, grounded in bullets; no fluff.\n"
        "Return plain text, lines start with '- Label: text'"
    )
    try:
        txt = "\n".join(f"- {n['label']}: " + "; ".join(n.get("bullets", [])) for n in notes)
        resp = client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[
                {"role":"system","content": prompt},
                {"role":"user","content": txt}
            ]
        )
        out = (resp.choices[0].message.content or "").strip()
        lines = [l.strip("- ").strip() for l in out.splitlines() if l.strip()]
        res: Dict[str,str] = {}
        for l in lines:
            if ":" in l:
                lab, body = l.split(":",1)
                res[lab.strip()] = body.strip()
        return res
    except Exception:
        return {}

# =========================
# CHAT AGENT
# =========================
CHAT_POLICY = (
    "ROLE\n"
    "You are a concise interviewer. Goals:\n"
    "1) Identify PUBLIC items (book, podcast, person, tool, film).\n"
    "2) Get the user's personal insight/practice about them.\n\n"
    "RULES\n"
    "- Exactly ONE short question per turn.\n"
    "- If the user mentioned a PUBLIC item, do not ask for confirmation.\n"
    "- Keep it warm, specific, professional; no fluff.\n"
)

def state_summary() -> str:
    parts = []
    for sid in st.session_state.slot_order:
        s = st.session_state.slots.get(sid)
        if not s:
            parts.append(f"{sid}: (empty)")
            continue
        done = "done" if s.get("done") else "open"
        parts.append(f"{sid}: {s.get('label','(pending)')} [{done}]")
    return "STATE\n" + " | ".join(parts) + f"\nCURRENT_SLOT_ID={current_slot_id()}"

def chat_reply() -> str:
    msgs = [
        {"role":"system","content": CHAT_POLICY},
        {"role":"system","content": state_summary()}
    ]
    tail = [m for m in st.session_state.history if m["role"] in ("user","assistant")]
    tail = tail[-6:]
    msgs.extend(tail)

    res = client.chat.completions.create(model=OPENAI_MODEL, messages=msgs)
    text = (res.choices[0].message.content or "").strip()
    if not text or not text.endswith("?"):
        text = "What changed in your practice after this?"
    return text

# =========================
# ORCHESTRATOR
# =========================
class Orchestrator:
    def __init__(self):
        self.slots = st.session_state.slots
        self.media_jobs = st.session_state.media_jobs
        self.executor: ThreadPoolExecutor = st.session_state.executor
        self.fp = st.session_state.media_fingerprints

    def upsert_slot(self, slot_id: str, label: Optional[str] = None,
                    bullets: Optional[List[str]] = None, done: Optional[bool] = None):
        s = self.slots.get(slot_id, {
            "slot_id": slot_id,
            "label": "",
            "bullets": [],
            "done": False,
            "media": {"status":"pending","best_image_url":"","candidates":[],"notes":""}
        })
        if label is not None: s["label"] = label[:120]
        if bullets is not None: s["bullets"] = [b.strip() for b in bullets][:4]
        if done is not None: s["done"] = bool(done)
        self.slots[slot_id] = s

    def schedule_media_search(self, slot_id: str, entity_type: str, entity_name: str):
        key = f"{entity_type}|{entity_name}".lower().strip()
        if key in self.fp:
            return  # already scheduled
        self.fp.add(key)

        s = self.slots.get(slot_id) or {
            "slot_id": slot_id, "label":"", "bullets":[], "done": False,
            "media": {"status":"pending","best_image_url":"","candidates":[],"notes":""}
        }
        s["media"] = {"status":"searching","best_image_url":"","candidates":[],"notes":""}
        self.slots[slot_id] = s

        fut = self.executor.submit(self._media_job, slot_id, entity_type, entity_name)
        job_id = str(uuid.uuid4())[:8]
        self.media_jobs[job_id] = (slot_id, fut)
        st.toast("ðŸ”Ž Image search startedâ€¦", icon="ðŸ–¼ï¸")

    def _media_job(self, slot_id: str, entity_type: str, entity_name: str) -> Dict[str, Any]:
        res = hosted_search_best_image(entity_type, entity_name)
        if res.get("status") == "found":
            res["slot_id"] = slot_id
            return res

        # Patch (2): On error, return status=error with notes (do not go to placeholder yet)
        if res.get("status") == "error":
            res["slot_id"] = slot_id
            return res

        # Only if genuinely none: generate placeholder
        return {
            "slot_id": slot_id,
            "status":"generated",
            "best_image_url": generate_placeholder_icon(entity_name or entity_type, slot_id),
            "candidates": [],
            "notes": "placeholder"
        }

    def poll_media(self) -> List[str]:
        updated = []
        to_delete = []
        for job_id, (slot_id, fut) in list(self.media_jobs.items()):
            if fut.done():
                try:
                    res = fut.result()
                    s = self.slots.get(slot_id)
                    if s:
                        m = s["media"]
                        m["status"] = res.get("status","none")
                        m["best_image_url"] = res.get("best_image_url","")
                        m["candidates"] = res.get("candidates",[])
                        m["notes"] = res.get("notes","")
                        updated.append(slot_id)
                finally:
                    to_delete.append(job_id)
        for j in to_delete:
            del self.media_jobs[j]
        return updated

    def finalize(self) -> Dict[str, Any]:
        notes = []
        for sid in st.session_state.slot_order:
            s = self.slots.get(sid)
            if not s: continue
            if s.get("label") and s.get("bullets"):
                notes.append({"label": s["label"], "bullets": s["bullets"]})
        if len(notes) < 4:
            return {"ok": False, "error": "Need 4 filled slots"}
        final = finalize_card_with_gpt(notes)
        st.session_state.final_lines = final or {}
        return {"ok": bool(final)}

# =========================
# FLOW: on user message
# =========================
def process_user_message(text: str, orch: Orchestrator):
    # 1) Detect public entity (fast heuristic + GPT router)
    e_type, e_name = normalize_entity(text)
    if not e_type:
        e_type, e_name = route_entity_with_gpt(text)

    # If public entity: create/assign slot & schedule search
    if e_type and e_type != "none" and e_name:
        sid = current_slot_id()
        label_hint = {
            "book":"Must-Read",
            "podcast":"Podcast",
            "person":"Role Model",
            "tool":"Go-to Tool",
            "film":"Influence"
        }.get(e_type, "Item")
        orch.upsert_slot(sid, label=f"{label_hint} â€” {e_name}", bullets=None, done=False)
        orch.schedule_media_search(sid, e_type, e_name)

    # 2) Distill insights from user's message into bullets (for current or next slot)
    sid2 = current_slot_id()
    hint = e_name or ""
    lab, bullets = distill_insights_with_gpt(text, context_hint=hint)
    if bullets:
        target_sid = sid2
        s_cur = st.session_state.slots.get(sid2)
        if s_cur and s_cur.get("media",{}).get("status") in ("searching","found","generated") and s_cur.get("bullets"):
            if st.session_state.current_slot_ix < 3:
                st.session_state.current_slot_ix += 1
                target_sid = current_slot_id()
        orch.upsert_slot(target_sid, label=lab or (hint if hint else "Practice"), bullets=bullets, done=True)
        # Advance after filling
        advance_slot()

    # 3) Generate next short question (always visible)
    reply = chat_reply()
    st.session_state.history.append({"role":"assistant","content": reply})

# =========================
# UI
# =========================
def render_progress_and_timeline():
    slots = st.session_state.slots
    filled = sum(1 for s in slots.values() if s.get("label") and s.get("bullets"))
    st.progress(min(1.0, filled/4), text=f"Progress: {filled}/4")

    cols = st.columns(4)
    for i, sid in enumerate(st.session_state.slot_order):
        s = slots.get(sid)
        with cols[i]:
            st.markdown(f"**{(s or {}).get('label') or sid}**")
            if not s:
                st.caption("(empty)")
                continue
            m = s.get("media",{})
            st.caption(f"status: {m.get('status') or 'pending'}")
            best = (m.get("best_image_url") or "").strip()
            if best:
                try: st.image(best, use_container_width=True)
                except Exception: st.caption("(image unavailable)")
            else:
                st.caption("(image pending)")
            # Show notes (Patch 2: surface errors)
            notes = (m.get("notes") or "").strip()
            if notes:
                st.code(notes, language="text")

def render_chat_history():
    for m in st.session_state.history:
        with st.chat_message(m["role"]):
            st.markdown(m["content"])

def render_overrides():
    st.subheader("Media Overrides (optional)")
    for sid, s in st.session_state.slots.items():
        with st.expander(f"Override for {s.get('label') or sid}"):
            c1, c2 = st.columns(2)
            with c1:
                url = st.text_input("Image URL (http/https)", key=f"url_{sid}")
                if url and url.startswith("http"):
                    s["media"]["status"] = "found"
                    s["media"]["best_image_url"] = url
                    s["media"]["notes"] = "override url"
                    st.success("Using URL override.")
            with c2:
                up = st.file_uploader("Upload image", type=["png","jpg","jpeg"], key=f"up_{sid}")
                if up:
                    path = save_uploaded_image(up, sid)
                    if path:
                        s["media"]["status"] = "uploaded"
                        s["media"]["best_image_url"] = path
                        s["media"]["notes"] = "uploaded file"
                        st.success("Using uploaded image.")

def render_final_card():
    lines = st.session_state.final_lines
    if not lines: return
    st.subheader("Your Expert Card")
    for sid in st.session_state.slot_order:
        s = st.session_state.slots.get(sid)
        if not s: continue
        label = s.get("label","").strip()
        if not label: continue
        line = lines.get(label,"").strip()
        if not line: continue
        best = (s.get("media",{}).get("best_image_url") or "").strip()
        cols = st.columns([1,2])
        with cols[0]:
            if best:
                try: st.image(best, use_container_width=True)
                except Exception: st.caption("(image unavailable)")
            else:
                st.caption("(image pending)")
        with cols[1]:
            st.markdown(f"**{label}**")
            st.write(line)

# =========================
# MAIN
# =========================
st.set_page_config(page_title=APP_TITLE, page_icon="ðŸŸ¡", layout="wide")
st.title(APP_TITLE)
st.caption("GPT-5 only â€¢ Hosted Web Search â€¢ Async media â€¢ One short question per turn")

client = get_client()
init_state()

# Preflight hosted web_search (once)
if st.session_state.web_search_ok is None:
    preflight_web_search()

if st.session_state.web_search_ok is False:
    st.error(f"Hosted web_search not available: {st.session_state.web_search_err}")

orch = Orchestrator()

# Poll media jobs every run
updated_slots = orch.poll_media()
if updated_slots:
    for sid in updated_slots:
        st.toast(f"Media updated: {sid}", icon="ðŸ–¼ï¸")

render_progress_and_timeline()
render_chat_history()

# Initial assistant question
if not any(m["role"] == "assistant" for m in st.session_state.history):
    st.session_state.history.append({
        "role":"assistant",
        "content":"Hi! Which single book most changed how you think about building data-driven products? Title only."
    })

# Chat input
user_text = st.chat_input("Your turnâ€¦")
if user_text:
    st.session_state.history.append({"role":"user","content": user_text})
    # Process immediately (entity routing, schedule media, insights, next question)
    process_user_message(user_text, orch)
    st.rerun()

# Action buttons
c1, c2, c3 = st.columns(3)
with c1:
    if st.button("âœ¨ Finalize (needs 4 slots)"):
        res = orch.finalize()
        if not res.get("ok"):
            st.warning(res.get("error","Could not finalize"))
        else:
            st.success("Finalized!")
            st.rerun()

with c2:
    if st.button("ðŸ”„ Restart"):
        try:
            st.session_state.executor.shutdown(cancel_futures=True)
        except Exception:
            pass
        for k in list(st.session_state.keys()):
            del st.session_state[k]
        st.rerun()

with c3:
    if st.button("ðŸ§¹ Clear Final"):
        st.session_state.final_lines = {}
        st.rerun()

render_final_card()
render_overrides()
